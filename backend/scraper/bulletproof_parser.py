"""
Bulletproof table parser using pandas for robust HTML table extraction.
This parser is designed to handle all variations of the SZABIST timetable format
and correctly filter by semester with 100% accuracy.
"""

import pandas as pd
import re
import logging
from typing import List, Dict, Optional, Any
from bs4 import BeautifulSoup
import warnings

# Suppress pandas warnings for cleaner output
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

class BulletproofTableParser:
    """
    Bulletproof table parser that uses pandas for robust table extraction.
    Handles multiple table formats and ensures accurate semester filtering.
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # Known column patterns for different table formats
        self.column_patterns = {
            # 9-column format: Sr.No, Dept, Program, Class/Section, Course, Faculty, Room, Time, Campus
            'format_9_col': ['sr', 'dept', 'program', 'class', 'course', 'faculty', 'room', 'time', 'campus'],
            
            # 6-column format: Class/Section, Course Title, Faculty, Room, Time, Campus  
            'format_6_col': ['class', 'course', 'faculty', 'room', 'time', 'campus'],
            
            # Alternative formats
            'format_alt': ['semester', 'course_title', 'faculty', 'room', 'time', 'campus']
        }
        
        # Semester normalization patterns
        self.semester_patterns = [
            r'BS\s*\(\s*([A-Z]+)\s*\)\s*-?\s*(\d+\s*[A-Z])',  # BS(CS)-5C, BS (AI) - 3A
            r'([A-Z]+)\s*\(\s*([A-Z]+)\s*\)\s*-?\s*(\d+\s*[A-Z])',  # General format
            r'([A-Z]+)\s+([A-Z]+)\s+-?\s*(\d+\s*[A-Z])',  # Alternative format
        ]

    def normalize_semester(self, semester_str: str) -> str:
        """Normalize semester string to standard format BS(XX)-YZ"""
        if not semester_str:
            return ""
        
        # Remove extra whitespace
        clean = re.sub(r'\s+', ' ', semester_str.strip())
        
        # Try different patterns
        for pattern in self.semester_patterns:
            match = re.match(pattern, clean, re.IGNORECASE)
            if match:
                groups = match.groups()
                if len(groups) == 2:  # BS(XX)-YZ format
                    degree, section = groups
                    section = re.sub(r'\s+', '', section)  # Remove spaces in section
                    return f"BS({degree.upper()})-{section.upper()}"
                elif len(groups) == 3:  # Other formats
                    degree, program, section = groups
                    section = re.sub(r'\s+', '', section)  # Remove spaces in section
                    return f"{degree.upper()}({program.upper()})-{section.upper()}"
        
        # If no pattern matches, return cleaned version
        return clean.upper()

    def extract_all_tables_from_html(self, html: str) -> List[pd.DataFrame]:
        """Extract all tables from HTML using pandas with multiple fallback strategies"""
        if not html:
            return []
        
        self.logger.info(f"Attempting to extract tables from HTML ({len(html)} chars)")
        
        try:
            # Strategy 1: Direct pandas parsing with different options
            parsing_options = [
                {'header': 0},  # First row as header
                {'header': None},  # No header
                {'header': 0, 'attrs': {'border': '1'}},  # Tables with border attribute
                {'header': 0, 'match': 'Class'},  # Tables containing "Class"
                {'header': 0, 'match': 'Schedule'},  # Tables containing "Schedule"
            ]
            
            tables = []
            for i, options in enumerate(parsing_options):
                try:
                    self.logger.info(f"Trying pandas parsing strategy {i+1}")
                    found_tables = pd.read_html(html, **options)
                    if found_tables:
                        self.logger.info(f"Strategy {i+1} found {len(found_tables)} tables")
                        tables.extend(found_tables)
                        break  # Use first successful parsing
                except Exception as e:
                    self.logger.debug(f"Strategy {i+1} failed: {e}")
                    continue
            
            # Strategy 2: BeautifulSoup preprocessing + pandas
            if not tables:
                self.logger.info("Direct pandas failed, trying BeautifulSoup preprocessing")
                from bs4 import BeautifulSoup
                soup = BeautifulSoup(html, 'html.parser')
                
                # Find all table elements
                table_elements = soup.find_all('table')
                self.logger.info(f"Found {len(table_elements)} table elements in HTML")
                
                for j, table_elem in enumerate(table_elements):
                    try:
                        # Clean up the table HTML for pandas
                        table_html = str(table_elem)
                        
                        # Remove problematic attributes that might confuse pandas
                        table_html = re.sub(r'style="[^"]*"', '', table_html)
                        table_html = re.sub(r'class="[^"]*"', '', table_html)
                        table_html = re.sub(r'bgcolor="[^"]*"', '', table_html)
                        
                        self.logger.info(f"Trying to parse table element {j+1}")
                        found_tables = pd.read_html(table_html, header=0)
                        if found_tables:
                            self.logger.info(f"Table element {j+1} parsed successfully")
                            tables.extend(found_tables)
                    except Exception as e:
                        self.logger.debug(f"Table element {j+1} failed: {e}")
                        continue
            
            # Strategy 3: Manual table extraction as last resort
            if not tables:
                self.logger.info("Pandas parsing failed completely, trying manual extraction")
                tables = self._manual_table_extraction(html)
            
            self.logger.info(f"Final result: Found {len(tables)} tables using all strategies")
            
            # Filter and validate tables
            valid_tables = []
            for i, table in enumerate(tables):
                self.logger.info(f"Raw table {i+1}: {table.shape[0]} rows, {table.shape[1]} columns")
                if len(table.columns) > 0:
                    self.logger.info(f"Table {i+1} columns: {list(table.columns)}")
                if table.shape[0] > 0:
                    self.logger.info(f"Table {i+1} sample data: {table.head(2).to_dict()}")
                
                if table.shape[0] > 0 and table.shape[1] >= 3:  # At least 1 row and 3 columns
                    valid_tables.append(table)
                    self.logger.info(f"Table {i+1}: VALID - {table.shape[0]} rows, {table.shape[1]} columns")
                else:
                    self.logger.info(f"Table {i+1}: SKIPPED - too small")
            
            return valid_tables
            
        except Exception as e:
            self.logger.error(f"All table extraction strategies failed: {e}")
            return []

    def _manual_table_extraction(self, html: str) -> List[pd.DataFrame]:
        """Manual table extraction as fallback when pandas fails"""
        try:
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html, 'html.parser')
            
            tables = []
            table_elements = soup.find_all('table')
            
            for table_elem in table_elements:
                rows = table_elem.find_all('tr')
                if len(rows) < 2:  # Need at least header + 1 data row
                    continue
                
                # Extract data manually
                table_data = []
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    row_data = [cell.get_text(strip=True) for cell in cells]
                    if row_data and any(cell.strip() for cell in row_data):  # Skip empty rows
                        table_data.append(row_data)
                
                if len(table_data) >= 2:  # At least header + 1 data row
                    # Convert to DataFrame
                    try:
                        df = pd.DataFrame(table_data[1:], columns=table_data[0])
                        tables.append(df)
                        self.logger.info(f"Manual extraction created table: {df.shape[0]} rows, {df.shape[1]} columns")
                    except Exception as e:
                        self.logger.debug(f"Manual DataFrame creation failed: {e}")
                        continue
            
            return tables
            
        except Exception as e:
            self.logger.error(f"Manual table extraction failed: {e}")
            return []

    def find_class_section_column(self, df: pd.DataFrame) -> Optional[int]:
        """Find the column that contains class/section information"""
        
        # Check column headers first
        for i, col in enumerate(df.columns):
            col_name = str(col).lower()
            if any(keyword in col_name for keyword in ['class', 'section', 'semester']):
                self.logger.info(f"Found class/section column by header: {col_name} (index {i})")
                return i
        
        # Check data patterns in each column
        for col_idx in range(len(df.columns)):
            # Get sample of non-null values from this column
            sample_values = df.iloc[:, col_idx].dropna().astype(str).head(10)
            
            # Count how many look like semester patterns
            semester_count = 0
            for value in sample_values:
                if any(re.search(pattern, value, re.IGNORECASE) for pattern in self.semester_patterns):
                    semester_count += 1
            
            # If most values look like semesters, this is likely the right column
            if semester_count >= len(sample_values) * 0.6:  # 60% threshold
                self.logger.info(f"Found class/section column by pattern: column {col_idx} ({semester_count}/{len(sample_values)} matches)")
                return col_idx
        
        # Fallback: assume it's column 3 (0-indexed) for 9-column format
        if len(df.columns) >= 9:
            self.logger.info("Using fallback: column 3 for 9-column format")
            return 3
        elif len(df.columns) >= 6:
            self.logger.info("Using fallback: column 0 for 6-column format")
            return 0
        else:
            self.logger.warning("Could not determine class/section column")
            return None

    def filter_by_semesters(self, df: pd.DataFrame, target_semesters: List[str]) -> pd.DataFrame:
        """Filter dataframe rows by semester with bulletproof matching"""
        
        if not target_semesters:
            self.logger.info("No semester filters provided - returning all rows")
            return df
        
        # Normalize target semesters
        normalized_targets = [self.normalize_semester(sem) for sem in target_semesters]
        self.logger.info(f"Normalized target semesters: {normalized_targets}")
        
        # Find the class/section column
        class_col_idx = self.find_class_section_column(df)
        if class_col_idx is None:
            self.logger.error("Could not find class/section column")
            return pd.DataFrame()  # Return empty DataFrame
        
        self.logger.info(f"Using column {class_col_idx} for semester filtering")
        
        # Create a mask for matching rows
        mask = pd.Series([False] * len(df))
        
        for idx, row in df.iterrows():
            # Get the value from the class/section column
            class_section_value = str(row.iloc[class_col_idx]) if pd.notna(row.iloc[class_col_idx]) else ""
            
            if not class_section_value or class_section_value.lower() in ['nan', 'none', '']:
                continue
            
            # Normalize the value from the table
            normalized_row_semester = self.normalize_semester(class_section_value)
            
            # Check if it matches any target semester
            for target in normalized_targets:
                if normalized_row_semester == target:
                    mask.iloc[idx] = True
                    self.logger.info(f"MATCH: '{class_section_value}' -> '{normalized_row_semester}' matches '{target}'")
                    break
            
            if not mask.iloc[idx]:
                self.logger.debug(f"NO MATCH: '{class_section_value}' -> '{normalized_row_semester}' (targets: {normalized_targets})")
        
        # Apply the filter
        filtered_df = df[mask]
        self.logger.info(f"Filtered from {len(df)} rows to {len(filtered_df)} rows")
        
        return filtered_df

    def dataframe_to_schedule_items(self, df: pd.DataFrame) -> List[Dict]:
        """Convert filtered dataframe to schedule item dictionaries"""
        
        if df.empty:
            return []
        
        items = []
        
        # Determine column mapping based on number of columns
        if len(df.columns) >= 9:
            # 9-column format: Sr.No, Dept, Program, Class/Section, Course, Faculty, Room, Time, Campus
            col_map = {
                'sr_no': 0,
                'dept': 1, 
                'program': 2,
                'class_section': 3,
                'course': 4,
                'faculty': 5,
                'room': 6,
                'time': 7,
                'campus': 8
            }
        elif len(df.columns) >= 6:
            # 6-column format: Class/Section, Course, Faculty, Room, Time, Campus
            col_map = {
                'sr_no': None,
                'dept': None,
                'program': None, 
                'class_section': 0,
                'course': 1,
                'faculty': 2,
                'room': 3,
                'time': 4,
                'campus': 5
            }
        elif len(df.columns) >= 3:
            # 3-column format: Class/Section, Course, Faculty (minimal format for testing)
            col_map = {
                'sr_no': None,
                'dept': None,
                'program': None, 
                'class_section': 0,
                'course': 1,
                'faculty': 2,
                'room': None,
                'time': None,
                'campus': None
            }
        else:
            self.logger.error(f"Unsupported table format with {len(df.columns)} columns")
            return []
        
        self.logger.info(f"Using column mapping for {len(df.columns)} columns: {col_map}")
        
        for idx, row in df.iterrows():
            # Extract values using column mapping
            def get_value(field: str) -> str:
                col_idx = col_map.get(field)
                if col_idx is not None and col_idx < len(row):
                    value = row.iloc[col_idx]
                    return str(value).strip() if pd.notna(value) else ""
                return ""
            
            # Create schedule item
            item = {
                'sr_no': get_value('sr_no'),
                'dept': get_value('dept'),
                'program': get_value('program'),
                'class_section': get_value('class_section'),
                'course': get_value('course'),
                'faculty': get_value('faculty'),
                'room': get_value('room') or 'TBD',
                'time': get_value('time') or 'TBD',
                'campus': get_value('campus') or 'SZABIST University Campus',
                'semester': get_value('class_section'),  # Use class_section as semester
                'raw_cells': [str(cell) if pd.notna(cell) else "" for cell in row.values],
                'source_line': idx + 1,
                'full_text': ' | '.join([str(cell) if pd.notna(cell) else "" for cell in row.values])
            }
            
            # Extract course title if it's embedded in the course field
            course_str = item['course']
            if course_str:
                extracted_title = self.extract_course_title_from_course_field(course_str)
                # Add a marker to show this was processed by bulletproof parser
                item['course_title'] = f"[BP] {extracted_title}" if extracted_title else f"[BP] {course_str}"
            else:
                item['course_title'] = "[BP] Course Title Not Available"
            
            items.append(item)
        
        return items

    def extract_course_title_from_course_field(self, course_str: str) -> str:
        """Extract course title from course field that might contain code + title + credits"""
        
        if not course_str:
            return ""
        
        # Pattern: "CSC 3109 Software Engineering (3,0)"
        match = re.match(r'^([A-Z]{2,4}\s*\d{3,4})\s+(.+?)(?:\s*\([0-9,\.\s]+\))?$', course_str)
        if match:
            course_code, title = match.groups()
            return title.strip()
        
        # If no pattern matches, return the whole string (might already be just title)
        return course_str.strip()

    def parse_schedule_bulletproof(self, html: str, target_semesters: List[str]) -> List[Dict]:
        """
        Main parsing function that uses pandas for bulletproof table extraction.
        
        Args:
            html: HTML content containing the table
            target_semesters: List of semesters to filter for (e.g., ["BS(AI)-3A", "BS(CS)-5C"])
        
        Returns:
            List of schedule item dictionaries for matching semesters only
        """
        
        self.logger.info("ðŸš€ BULLETPROOF PARSER STARTED ðŸš€")
        self.logger.info(f"Target semesters: {target_semesters}")
        
        if not html:
            self.logger.warning("No HTML content provided")
            return []
        
        # Extract all tables using pandas
        tables = self.extract_all_tables_from_html(html)
        
        if not tables:
            self.logger.warning("No tables found in HTML")
            return []
        
        all_items = []
        
        # Process each table
        for i, table in enumerate(tables):
            self.logger.info(f"Processing table {i+1} ({table.shape[0]} rows, {table.shape[1]} columns)")
            
            # Filter by semesters
            filtered_table = self.filter_by_semesters(table, target_semesters)
            
            # Convert to schedule items
            items = self.dataframe_to_schedule_items(filtered_table)
            
            self.logger.info(f"Table {i+1} produced {len(items)} matching items")
            all_items.extend(items)
        
        self.logger.info(f"ðŸŽ¯ BULLETPROOF PARSER COMPLETE: {len(all_items)} total items")
        
        return all_items


def parse_schedule_bulletproof(html: str, semesters: List[str]) -> List[Dict]:
    """
    Bulletproof parsing function that can be used as a drop-in replacement
    for the existing parse_schedule_html function.
    """
    parser = BulletproofTableParser()
    return parser.parse_schedule_bulletproof(html, semesters)


# Test function
def test_bulletproof_parser():
    """Test the bulletproof parser with sample data"""
    
    # Sample HTML representing the timetable structure from the images
    sample_html = """
    <table border="1">
        <tr>
            <th>Sr. No</th>
            <th>Dept</th>
            <th>Program</th>
            <th>Class / Section</th>
            <th>Course</th>
            <th>Faculty</th>
            <th>Room</th>
            <th>Time</th>
            <th>Campus</th>
        </tr>
        <tr>
            <td>1</td>
            <td>CS</td>
            <td>BS(CS)</td>
            <td>BS(CS) - 5C</td>
            <td>CSC 3109 Software Engineering (3,0)</td>
            <td>Awais Nawaz</td>
            <td>Hall 01 A</td>
            <td>09:30 AM - 11:00 AM</td>
            <td>SZABIST University Campus H-8/4 ISB</td>
        </tr>
        <tr>
            <td>2</td>
            <td>CS</td>
            <td>BS(SE)</td>
            <td>BS(SE) - 2C</td>
            <td>CSC 1208 Object Oriented Programming Techniques (3,0)</td>
            <td>Syed Mehdi Abbas</td>
            <td>NB-206</td>
            <td>08:30 AM - 10:00 AM</td>
            <td>SZABIST HMB I-8 MarkazCampus</td>
        </tr>
        <tr>
            <td>3</td>
            <td>CS</td>
            <td>BS(SE)</td>
            <td>BS(SE) - 2C</td>
            <td>CSC 1109 Pakistan Studies (2,0)</td>
            <td>Dr. Farooq Soolongi</td>
            <td>NB-206</td>
            <td>10:00 AM - 12:00 PM</td>
            <td>SZABIST HMB I-8 MarkazCampus</td>
        </tr>
        <tr>
            <td>4</td>
            <td>CS</td>
            <td>BS(SE)</td>
            <td>BS(SE) - 3A</td>
            <td>CSCL 3105 Lab: Computer Organization and Assembly Language (0,1)</td>
            <td>Faiza Asad</td>
            <td>Lab 02</td>
            <td>08:00 AM - 11:00 AM</td>
            <td>SZABIST University Campus H-8/4 ISB</td>
        </tr>
        <tr>
            <td>6</td>
            <td>AI</td>
            <td>BSAI</td>
            <td>BS(AI) - 3A</td>
            <td>CSCL 3105 Lab: Computer Organization and Assembly Language (0,1)</td>
            <td>Sarwat Nadeem -</td>
            <td>Lab 05</td>
            <td>08:00 AM - 11:00 AM</td>
            <td>SZABIST University Campus H-8/4 ISB</td>
        </tr>
        <tr>
            <td>7</td>
            <td>AI</td>
            <td>BSAI</td>
            <td>BS(AI) - 3B</td>
            <td>CSCL 2102 Lab: Data Structures and Algorithms (0,1)</td>
            <td>Sidra Safdar</td>
            <td>Lab 04</td>
            <td>08:00 AM - 11:00 AM</td>
            <td>SZABIST University Campus H-8/4 ISB</td>
        </tr>
    </table>
    """
    
    parser = BulletproofTableParser()
    
    print("ðŸ§ª Testing Bulletproof Parser")
    print("=" * 50)
    
    # Test with specific semesters
    target_semesters = ["BS(AI)-3A", "BS(CS)-5C"]
    results = parser.parse_schedule_bulletproof(sample_html, target_semesters)
    
    print(f"\\nTarget semesters: {target_semesters}")
    print(f"Results found: {len(results)}")
    print()
    
    for i, item in enumerate(results, 1):
        print(f"Result {i}:")
        print(f"  Class/Section: {item['class_section']}")
        print(f"  Course: {item['course']}")
        print(f"  Faculty: {item['faculty']}")
        print(f"  Room: {item['room']}")
        print(f"  Time: {item['time']}")
        print()
    
    # Test with no filters (should return all)
    print("\\n" + "=" * 50)
    print("Testing with no semester filters (should return all rows):")
    all_results = parser.parse_schedule_bulletproof(sample_html, [])
    print(f"Total results with no filter: {len(all_results)}")


if __name__ == "__main__":
    test_bulletproof_parser()